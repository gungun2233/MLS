{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step1: Data Collection/ Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 9)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\Asus\\OneDrive\\Desktop\\MLS\\MLS\\DL\\GA.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0           1        337          118                  4  4.5   4.5  9.65   \n",
       "1           2        324          107                  4  4.0   4.5  8.87   \n",
       "2           3        316          104                  3  3.0   3.5  8.00   \n",
       "3           4        322          110                  3  3.5   2.5  8.67   \n",
       "4           5        314          103                  2  2.0   3.0  8.21   \n",
       "\n",
       "   Research  Chance of Admit   \n",
       "0         1              0.92  \n",
       "1         1              0.76  \n",
       "2         1              0.72  \n",
       "3         1              0.80  \n",
       "4         0              0.65  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of      Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0             1        337          118                  4  4.5   4.5  9.65   \n",
       "1             2        324          107                  4  4.0   4.5  8.87   \n",
       "2             3        316          104                  3  3.0   3.5  8.00   \n",
       "3             4        322          110                  3  3.5   2.5  8.67   \n",
       "4             5        314          103                  2  2.0   3.0  8.21   \n",
       "..          ...        ...          ...                ...  ...   ...   ...   \n",
       "395         396        324          110                  3  3.5   3.5  9.04   \n",
       "396         397        325          107                  3  3.0   3.5  9.11   \n",
       "397         398        330          116                  4  5.0   4.5  9.45   \n",
       "398         399        312          103                  3  3.5   4.0  8.78   \n",
       "399         400        333          117                  4  5.0   4.0  9.66   \n",
       "\n",
       "     Research  Chance of Admit   \n",
       "0           1              0.92  \n",
       "1           1              0.76  \n",
       "2           1              0.72  \n",
       "3           1              0.80  \n",
       "4           0              0.65  \n",
       "..        ...               ...  \n",
       "395         1              0.82  \n",
       "396         1              0.84  \n",
       "397         1              0.91  \n",
       "398         0              0.67  \n",
       "399         1              0.95  \n",
       "\n",
       "[400 rows x 9 columns]>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Serial No.', 'GRE Score', 'TOEFL Score', 'University Rating',\n",
       "       'SOP', 'LOR ', 'CGPA', 'Research', 'Chance of Admit '],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Serial No.', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research  \\\n",
       "0        337          118                  4  4.5   4.5  9.65         1   \n",
       "1        324          107                  4  4.0   4.5  8.87         1   \n",
       "2        316          104                  3  3.0   3.5  8.00         1   \n",
       "3        322          110                  3  3.5   2.5  8.67         1   \n",
       "4        314          103                  2  2.0   3.0  8.21         0   \n",
       "\n",
       "   Chance of Admit   \n",
       "0              0.92  \n",
       "1              0.76  \n",
       "2              0.72  \n",
       "3              0.80  \n",
       "4              0.65  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.iloc[:,0:-1]\n",
    "y=df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>324</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>325</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>330</td>\n",
       "      <td>116</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>333</td>\n",
       "      <td>117</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.66</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research\n",
       "0          337          118                  4  4.5   4.5  9.65         1\n",
       "1          324          107                  4  4.0   4.5  8.87         1\n",
       "2          316          104                  3  3.0   3.5  8.00         1\n",
       "3          322          110                  3  3.5   2.5  8.67         1\n",
       "4          314          103                  2  2.0   3.0  8.21         0\n",
       "..         ...          ...                ...  ...   ...   ...       ...\n",
       "395        324          110                  3  3.5   3.5  9.04         1\n",
       "396        325          107                  3  3.0   3.5  9.11         1\n",
       "397        330          116                  4  5.0   4.5  9.45         1\n",
       "398        312          103                  3  3.5   4.0  8.78         0\n",
       "399        333          117                  4  5.0   4.0  9.66         1\n",
       "\n",
       "[400 rows x 7 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.92\n",
       "1      0.76\n",
       "2      0.72\n",
       "3      0.80\n",
       "4      0.65\n",
       "       ... \n",
       "395    0.82\n",
       "396    0.84\n",
       "397    0.91\n",
       "398    0.67\n",
       "399    0.95\n",
       "Name: Chance of Admit , Length: 400, dtype: float64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>301</td>\n",
       "      <td>97</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>334</td>\n",
       "      <td>119</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>305</td>\n",
       "      <td>112</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.65</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>307</td>\n",
       "      <td>109</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>318</td>\n",
       "      <td>106</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.92</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>307</td>\n",
       "      <td>110</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>321</td>\n",
       "      <td>111</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>325</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>326</td>\n",
       "      <td>111</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>300</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>320 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research\n",
       "93         301           97                  2  3.0   3.0  7.88         1\n",
       "23         334          119                  5  5.0   4.5  9.70         1\n",
       "299        305          112                  3  3.0   3.5  8.65         0\n",
       "13         307          109                  3  4.0   3.0  8.00         1\n",
       "90         318          106                  2  4.0   4.0  7.92         1\n",
       "..         ...          ...                ...  ...   ...   ...       ...\n",
       "255        307          110                  4  4.0   4.5  8.37         0\n",
       "72         321          111                  5  5.0   5.0  9.45         1\n",
       "396        325          107                  3  3.0   3.5  9.11         1\n",
       "235        326          111                  5  4.5   4.0  9.23         1\n",
       "37         300          105                  1  1.0   2.0  7.80         0\n",
       "\n",
       "[320 rows x 7 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "SCALAR = MinMaxScaler()\n",
    "X_train_scaled = SCALAR.fit_transform(X_train)\n",
    "X_test_scaled = SCALAR.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.22      , 0.17857143, 0.25      , ..., 0.42857143, 0.25      ,\n",
       "        1.        ],\n",
       "       [0.88      , 0.96428571, 1.        , ..., 0.85714286, 0.91911765,\n",
       "        1.        ],\n",
       "       [0.3       , 0.71428571, 0.5       , ..., 0.57142857, 0.53308824,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.7       , 0.53571429, 0.5       , ..., 0.57142857, 0.70220588,\n",
       "        1.        ],\n",
       "       [0.72      , 0.67857143, 1.        , ..., 0.71428571, 0.74632353,\n",
       "        1.        ],\n",
       "       [0.2       , 0.46428571, 0.        , ..., 0.14285714, 0.22058824,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(7,activation=\"relu\",input_dim=7))\n",
    "model.add(Dense(7,activation=\"relu\"))\n",
    "model.add(Dense(1,activation=\"linear\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │            \u001b[38;5;34m56\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │            \u001b[38;5;34m56\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m8\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">120</span> (480.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m120\u001b[0m (480.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">120</span> (480.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m120\u001b[0m (480.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - loss: 1.6799 - val_loss: 1.6143\n",
      "Epoch 2/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.4185 - val_loss: 1.3942\n",
      "Epoch 3/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.2496 - val_loss: 1.2069\n",
      "Epoch 4/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0788 - val_loss: 1.0472\n",
      "Epoch 5/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.9037 - val_loss: 0.9116\n",
      "Epoch 6/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.7970 - val_loss: 0.7941\n",
      "Epoch 7/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.7380 - val_loss: 0.6891\n",
      "Epoch 8/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6058 - val_loss: 0.5932\n",
      "Epoch 9/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5057 - val_loss: 0.5037\n",
      "Epoch 10/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.4538 - val_loss: 0.4197\n",
      "Epoch 11/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3686 - val_loss: 0.3413\n",
      "Epoch 12/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.3138 - val_loss: 0.2662\n",
      "Epoch 13/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.2427 - val_loss: 0.1931\n",
      "Epoch 14/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.1695 - val_loss: 0.1251\n",
      "Epoch 15/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.1045 - val_loss: 0.0726\n",
      "Epoch 16/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0594 - val_loss: 0.0405\n",
      "Epoch 17/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0358 - val_loss: 0.0235\n",
      "Epoch 18/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0215 - val_loss: 0.0167\n",
      "Epoch 19/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0153 - val_loss: 0.0145\n",
      "Epoch 20/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0138 - val_loss: 0.0136\n",
      "Epoch 21/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0134 - val_loss: 0.0128\n",
      "Epoch 22/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - loss: 0.0132 - val_loss: 0.0120\n",
      "Epoch 23/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0118 - val_loss: 0.0114\n",
      "Epoch 24/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0135 - val_loss: 0.0108\n",
      "Epoch 25/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0104 - val_loss: 0.0103\n",
      "Epoch 26/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0113 - val_loss: 0.0098\n",
      "Epoch 27/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0109 - val_loss: 0.0094\n",
      "Epoch 28/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0096 - val_loss: 0.0090\n",
      "Epoch 29/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0084 - val_loss: 0.0087\n",
      "Epoch 30/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0093 - val_loss: 0.0084\n",
      "Epoch 31/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0078 - val_loss: 0.0081\n",
      "Epoch 32/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0075 - val_loss: 0.0079\n",
      "Epoch 33/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0075 - val_loss: 0.0076\n",
      "Epoch 34/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0085 - val_loss: 0.0074\n",
      "Epoch 35/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0074 - val_loss: 0.0072\n",
      "Epoch 36/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0065 - val_loss: 0.0071\n",
      "Epoch 37/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0081 - val_loss: 0.0069\n",
      "Epoch 38/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0076 - val_loss: 0.0068\n",
      "Epoch 39/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0066 - val_loss: 0.0067\n",
      "Epoch 40/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0061 - val_loss: 0.0065\n",
      "Epoch 41/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0064 - val_loss: 0.0064\n",
      "Epoch 42/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0067 - val_loss: 0.0063\n",
      "Epoch 43/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0057 - val_loss: 0.0062\n",
      "Epoch 44/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0054 - val_loss: 0.0061\n",
      "Epoch 45/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0058 - val_loss: 0.0060\n",
      "Epoch 46/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0062 - val_loss: 0.0060\n",
      "Epoch 47/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0062 - val_loss: 0.0059\n",
      "Epoch 48/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0057 - val_loss: 0.0058\n",
      "Epoch 49/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0056 - val_loss: 0.0057\n",
      "Epoch 50/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0061 - val_loss: 0.0056\n",
      "Epoch 51/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0054 - val_loss: 0.0056\n",
      "Epoch 52/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0053 - val_loss: 0.0056\n",
      "Epoch 53/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0052 - val_loss: 0.0056\n",
      "Epoch 54/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0051 - val_loss: 0.0056\n",
      "Epoch 55/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0049 - val_loss: 0.0056\n",
      "Epoch 56/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0049 - val_loss: 0.0055\n",
      "Epoch 57/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0054 - val_loss: 0.0055\n",
      "Epoch 58/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0049 - val_loss: 0.0055\n",
      "Epoch 59/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0048 - val_loss: 0.0055\n",
      "Epoch 60/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0056 - val_loss: 0.0054\n",
      "Epoch 61/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0055 - val_loss: 0.0055\n",
      "Epoch 62/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0048 - val_loss: 0.0055\n",
      "Epoch 63/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0045 - val_loss: 0.0055\n",
      "Epoch 64/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0056 - val_loss: 0.0054\n",
      "Epoch 65/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0049 - val_loss: 0.0054\n",
      "Epoch 66/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0044 - val_loss: 0.0054\n",
      "Epoch 67/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0048 - val_loss: 0.0054\n",
      "Epoch 68/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0050 - val_loss: 0.0053\n",
      "Epoch 69/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0061 - val_loss: 0.0053\n",
      "Epoch 70/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0044 - val_loss: 0.0053\n",
      "Epoch 71/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0056 - val_loss: 0.0052\n",
      "Epoch 72/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0054 - val_loss: 0.0052\n",
      "Epoch 73/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0046 - val_loss: 0.0053\n",
      "Epoch 74/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0052 - val_loss: 0.0053\n",
      "Epoch 75/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0044 - val_loss: 0.0052\n",
      "Epoch 76/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0046 - val_loss: 0.0052\n",
      "Epoch 77/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0042 - val_loss: 0.0052\n",
      "Epoch 78/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0044 - val_loss: 0.0052\n",
      "Epoch 79/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0053 - val_loss: 0.0052\n",
      "Epoch 80/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0048 - val_loss: 0.0052\n",
      "Epoch 81/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0039 - val_loss: 0.0051\n",
      "Epoch 82/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0048 - val_loss: 0.0051\n",
      "Epoch 83/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0048 - val_loss: 0.0052\n",
      "Epoch 84/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0043 - val_loss: 0.0051\n",
      "Epoch 85/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0033 - val_loss: 0.0051\n",
      "Epoch 86/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0050 - val_loss: 0.0050\n",
      "Epoch 87/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0049 - val_loss: 0.0051\n",
      "Epoch 88/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0044 - val_loss: 0.0051\n",
      "Epoch 89/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0039 - val_loss: 0.0050\n",
      "Epoch 90/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0045 - val_loss: 0.0051\n",
      "Epoch 91/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0046 - val_loss: 0.0050\n",
      "Epoch 92/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0046 - val_loss: 0.0050\n",
      "Epoch 93/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0039 - val_loss: 0.0050\n",
      "Epoch 94/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0040 - val_loss: 0.0050\n",
      "Epoch 95/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0047 - val_loss: 0.0050\n",
      "Epoch 96/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0046 - val_loss: 0.0050\n",
      "Epoch 97/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0040 - val_loss: 0.0050\n",
      "Epoch 98/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0039 - val_loss: 0.0050\n",
      "Epoch 99/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0041 - val_loss: 0.0050\n",
      "Epoch 100/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0039 - val_loss: 0.0050\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer='Adam')\n",
    "history=model.fit(X_train_scaled, y_train, epochs=100, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 7 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000023871421800> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 103ms/stepWARNING:tensorflow:6 out of the last 9 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000023871421800> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred=model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.799512545648486"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x23872b7e0c0>]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
